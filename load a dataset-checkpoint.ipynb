{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 77s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "#include_top=False removes the output layer of the model\n",
    "base_model = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get only the name\n",
    "base_model.layers[0].__class__.__name__\n",
    "\n",
    "#To see the input/output of a particular layer\n",
    "base_model.layers[0].input\n",
    "\n",
    "#Freezing all the layers by making their trainable=False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "#Checking this\n",
    "base_model.layers[12].trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(base_model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block5_pool/MaxPool:0' shape=(None, 7, 7, 512) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ouput of the current model\n",
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we add our dense layers for a new prediction on top of the base model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "top_model = base_model.output\n",
    "top_model = Flatten()(top_model)\n",
    "top_model = Dense(512, activation='relu')(top_model)   #First added FCL dense layer\n",
    "top_model = Dense(512, activation='relu')(top_model)    #Second added FCL dense layer\n",
    "top_model = Dense(256, activation='relu')(top_model)    #Third added FCL dense layer\n",
    "top_model = Dense(7, activation='softmax')(top_model)    #Output layer with 2 class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Softmax:0' shape=(None, 7) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's see the top_model output\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMP: Mounting the base_model with the top_model and forming newmodel\n",
    "\n",
    "from keras.models import Model\n",
    "newmodel = Model(inputs=base_model.input, outputs=top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Softmax:0' shape=(None, 7) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x191ed958808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed95f408>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed95fec8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x191ed9c0448>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9c0c08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9cf708>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x191ed9cf388>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9d2508>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9dac08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9e0148>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x191ed9e8d48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9e85c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9f3788>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191ed9fe648>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x191eda04948>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191eda04748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191eda0d808>,\n",
       " <keras.layers.convolutional.Conv2D at 0x191eda14cc8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x191eda1cb88>,\n",
       " <keras.layers.core.Flatten at 0x191eda65d08>,\n",
       " <keras.layers.core.Dense at 0x191eda65d48>,\n",
       " <keras.layers.core.Dense at 0x191eda69148>,\n",
       " <keras.layers.core.Dense at 0x191edbab6c8>,\n",
       " <keras.layers.core.Dense at 0x191edbab988>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 27,956,039\n",
      "Trainable params: 13,241,351\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 images belonging to 4 classes.\n",
      "Found 628 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#Converting to 4D\\nfor img_test in test_generator:\\n    img_test=np.expand_dims(img_test, axis=0)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing our images for recognition\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data=\"\\\\Users/DELL/Desktop/Face/train/\"\n",
    "test_data=\"\\\\Users/DELL/Desktop/Face/test/\"\n",
    "\n",
    "#Data image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical')\n",
    "\n",
    "'''#Converting to 4D\n",
    "for img_train in train_generator:\n",
    "    img_train=np.expand_dims(img_train, axis=0)'''\n",
    " \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "'''#Converting to 4D\n",
    "for img_test in test_generator:\n",
    "    img_test=np.expand_dims(img_test, axis=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
